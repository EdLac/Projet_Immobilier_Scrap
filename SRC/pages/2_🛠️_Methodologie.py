import streamlit as st

# Configuration de la page
st.set_page_config(layout="wide", page_title="M√©thodologie ‚Äì Scraping & Cleaning")

st.title("üß™ M√©thodologie ‚Äì Scraping & Nettoyage des donn√©es immobili√®res")

# Onglets
tabs = st.tabs(["üîç Scraping", "üßπ Cleaning / ETL"])


# Onglet 1 : Scraping

with tabs[0]:
    st.header("üîç √âtape 1 ‚Äì Scraping")
    st.markdown("""
    Le scraping consiste √† **collecter automatiquement les annonces immobili√®res** depuis ParuVendu.fr.
    
    ### M√©thode
    - Requ√™tes HTTP avec `requests` et User-Agent personnalis√©.
    - Parsing HTML avec `BeautifulSoup`.
    - Extraction des informations cl√©s :
      - **Titre** et **lien** de l'annonce
      - **Prix**
      - **Ville**
      - **Description courte**
      - **D√©tails** (pi√®ces, chambres, options comme garage, balcon, ascenseur)
      - **Localisation** de l‚Äôannonce

    ### Gestion des enjeux
    - D√©tection et arr√™t en cas de **CAPTCHA** pour √©viter le blocage.
    - Limitation du nombre d'annonces par ex√©cution (`MAX_ANNONCES_PAR_RUN`).
    - Checkpointing : sauvegarde automatique de la derni√®re ville et page pour pouvoir **reprendre le scraping en cas d‚Äôinterruption**.
    - Fusion et d√©duplication avec les anciennes annonces pour √©viter les doublons.

    ### Difficult√©s surmont√©es
    - Structure HTML variable selon les annonces.
    - Informations manquantes ou mal format√©es.
    - Gestion de volumes importants de donn√©es.
    - Besoin de ralentir les requ√™tes pour ne pas √™tre bloqu√©.

    ### R√©sultat
    √Ä la fin du scraping, on obtient un fichier CSV brut (**ANNONCES_RAW.csv**) contenant pour chaque annonce :
    - Ville, titre, lien, description, prix, localisation, d√©tails
    - Chaque ligne correspond √† une annonce unique, mais **les donn√©es peuvent encore contenir des doublons, des valeurs manquantes ou mal format√©es**.
    """)


# Onglet 2 : Cleaning / ETL

with tabs[1]:
    st.header("üßπ √âtape 2 ‚Äì Nettoyage et ETL")
    st.markdown("""
    Apr√®s le scraping, les donn√©es brutes sont transform√©es pour devenir **fiables et exploitables**.

    ### √âtapes de nettoyage
    - Standardisation des noms de villes et des types de biens.
    - Nettoyage des textes (`Description`, `D√©tails`) pour supprimer retours √† la ligne, espaces inutiles ou caract√®res sp√©ciaux.
    - Extraction des informations des d√©tails :
      - Nombre de pi√®ces et chambres
      - Options : garage, balcon, ascenseur
      - Terrain, DPE
    - Conversion des prix et surfaces en valeurs num√©riques.
    - D√©tection et suppression des doublons.
    - Filtrage des biens ind√©sirables (terrains, garages, commerces, h√¥tels...).
    - Suppression des valeurs aberrantes (outliers) sur le prix et le prix au m¬≤.
    - Optionnel : g√©ocodage pour obtenir latitude et longitude.

    ### Difficult√©s surmont√©es
    - Valeurs manquantes ou incoh√©rentes dans certains champs.
    - Formats diff√©rents pour le prix, la surface et les d√©tails.
    - Extraction des informations √† partir de cha√Ænes de texte complexes.
    - Besoin de standardiser les types de biens pour l‚Äôanalyse.

    ### R√©sultat
    √Ä la fin du nettoyage, on obtient un fichier CSV propre (**ANNONCES_CLEAN.csv**) contenant pour chaque annonce :
    - Ville standardis√©e
    - Type de bien homog√®ne
    - Prix de vente et prix au m¬≤
    - Surface, nombre de pi√®ces et chambres
    - Options : garage, balcon, ascenseur
    - Terrain et DPE si disponibles
    - Localisation exploitable et √©ventuellement coordonn√©es GPS
    - Donn√©es d√©dupliqu√©es, filtr√©es et pr√™tes pour analyse et visualisations
    """)
