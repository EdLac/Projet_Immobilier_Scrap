import streamlit as st
from theme import load_css, load_matplotlib_theme

# ------------------------------------------------------------
# THEME GLOBAL
# ------------------------------------------------------------
load_css()
load_matplotlib_theme()

# ------------------------------------------------------------
# PAGE CONTENT
# ------------------------------------------------------------
st.title("üß™ M√©thodologie ‚Äì Scraping & Nettoyage des donn√©es immobili√®res")

# Onglets
tabs = st.tabs(["üîç Scraping", "üßπ Cleaning / ETL"])

# ------------------------------------------------------------
# ONGLET 1 : SCRAPING
# ------------------------------------------------------------
with tabs[0]:
    st.header("üîç √âtape 1 ‚Äì Scraping")
    st.markdown("""
    Le scraping consiste √† **collecter automatiquement les annonces immobili√®res**
    depuis ParuVendu.fr.
    
    ### M√©thode
    - Requ√™tes HTTP avec `requests` et User-Agent personnalis√©.
    - Parsing HTML avec `BeautifulSoup`.
    - Extraction des informations cl√©s :
      - **Titre** et **lien** de l'annonce
      - **Prix**
      - **Ville**
      - **Description courte**
      - **D√©tails** (pi√®ces, chambres, options comme garage, balcon, ascenseur)
      - **Localisation** de l‚Äôannonce

    ### Gestion des enjeux
    - D√©tection et arr√™t en cas de **CAPTCHA** pour √©viter le blocage.
    - Limitation du nombre d'annonces par ex√©cution (`MAX_ANNONCES_PAR_RUN`).
    - Checkpointing : sauvegarde automatique de la derni√®re ville et page
      pour pouvoir **reprendre le scraping en cas d‚Äôinterruption**.
    - Fusion et d√©duplication avec les anciennes annonces pour √©viter les doublons.

    ### Difficult√©s surmont√©es
    - Structure HTML variable selon les annonces.
    - Informations manquantes ou mal format√©es.
    - Gestion de volumes importants de donn√©es.
    - N√©cessit√© de ralentir les requ√™tes pour ne pas √™tre bloqu√©.

    ### R√©sultat
    √Ä la fin du scraping, on obtient un fichier CSV brut
    (**ANNONCES_RAW.csv**) contenant :
    - Ville, titre, lien, description, prix, localisation, d√©tails
    - Donn√©es encore susceptibles de contenir doublons ou valeurs manquantes
    """)

# ------------------------------------------------------------
# ONGLET 2 : CLEANING / ETL
# ------------------------------------------------------------
with tabs[1]:
    st.header("üßπ √âtape 2 ‚Äì Nettoyage et ETL")
    st.markdown("""
    Apr√®s le scraping, les donn√©es brutes sont transform√©es pour devenir
    **fiables et exploitables**.

    ### √âtapes de nettoyage
    - Standardisation des noms de villes et des types de biens.
    - Nettoyage des textes (`description`, `d√©tails`).
    - Extraction des informations :
      - Nombre de pi√®ces et chambres
      - Options : garage, balcon, ascenseur
      - Terrain, DPE
    - Conversion des prix et surfaces en valeurs num√©riques.
    - D√©tection et suppression des doublons.
    - Filtrage des biens ind√©sirables (terrains, garages, commerces‚Ä¶).
    - Suppression des valeurs aberrantes (outliers).
    - Optionnel : g√©ocodage (latitude / longitude).

    ### Difficult√©s surmont√©es
    - Donn√©es manquantes ou incoh√©rentes.
    - Formats h√©t√©rog√®nes (prix, surfaces, textes).
    - Extraction complexe √† partir de descriptions libres.

    ### R√©sultat
    Le nettoyage produit un fichier CSV propre
    (**ANNONCES_CLEAN.csv**) pr√™t pour l‚Äôanalyse et les visualisations.
    """)


